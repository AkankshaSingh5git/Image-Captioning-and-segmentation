# Image-Captioning-and-segmentation




## Dataset

This project uses the [Flickr8k dataset](https://www.kaggle.com/datasets/adityajn105/flickr8k) from Kaggle.  
Please download it from the above link and place it in your local environment if you want to run the full code and experiments.

## Description

This repository contains code for image captioning and segmentation using deep learning techniques.  
It combines CNN-based feature extraction and LSTM-based sequence modeling to generate captions for images.

## Files

- `main.py` — Main training and evaluation script.
- `.ipynb` files — Notebooks with experiments and visualizations.
- `model.keras` — Trained Keras model.
- `tokenizer.pkl` — Tokenizer used for captions.

## How to Run

1. Clone this repository.
2. Download the dataset from Kaggle and place images and captions in your project folder.
3. Install requirements (`pip install -r requirements.txt` if you have one).
4. Run `main.py` or open notebooks to start experimenting.

## License

This project is for academic and research purposes only.
